 There's this narrative, like LM, replacing jobs, replacing programs, and particular. Especially in terms of like three-to-can students, I'll say like, even if you want to get into AI, there's always a value in having good software fundamentals, software engineering fundamentals, programming fundamentals, really understanding like foundations of AI, which include things like probability and statistics. I have a picture, pinned to my wall, image, you and me, laughing, loving it all. But look at our life now, all tired and torn. We've mustn't fight and delight in the tears that won't cry and feel done. All be now. Whoa! Welcome back to the Free Code Camp podcast. I'm Quincy Larsen Teacher and founder of FreeCodeCamp.org. Each week, we're bringing you insight from developers, founders, and ambitious people getting into tech. And this week, we're talking with EFON My, a senior software engineer on Google's TensorFlow team, who left the private sector behind to go to AI research at Stanford. EFON is currently lead maintainer of the open source helm project, where he benchmarks the performance of large language models. EFON, welcome to the show. Thanks so much for having me Quincy. It's all good to be here. Yeah, and I'm hyped to have you here because you have the benefit of having worked in the private sector as a software engineer and now also as a researcher at Stanford. So you work as a, doing like hardcore software engineering on Google's TensorFlow team. And now you're working doing like hardcore cutting edge research with these emerging models and figuring out how good they actually are. And that's like super, super exciting to me. Yeah, I'm really glad to be talking about this stuff. Yeah, and I'll just give the audience some perspective on how you and I met. So I went to this event in Singapore or it wasn't in Singapore, but it was it might as well as I thought it was like tons of Singaporeans in San Francisco. And of course you grew up in Singapore? Yes, I grew up in Singapore. I moved here in the 2010. So I've been in the Bay of San Francisco Bay of F about 14 years now. Yeah, and you've really made like good use of time. And you've been working as an international student or how did you get here? Yeah, so I was originally, so I grew up in Singapore. I did most of my schooling in Singapore. I moved here for university. So I did my undergrad at Stanford. And that's when I came here. And I stayed here. I basically stayed on after that and kept working here. And that's where. And then I did my undergrad in Massachusetts at Stanford. And now I working at Stanford. I like to joke it's a bit like moving back at the parents house. Yeah, but it's like I've been enjoying being the baby. And is it common for someone to just leave? Because I mean, people leave academia all the time for the eye, paying like fancy, you know, jobs, cushy jobs in Silicon Valley, in New York City, places like that. But is it common for someone to leave that life behind? Volunteerally just like sit down the tools and go, basically do something almost completely different. Doing research is very different from applying tools. Or maybe you're doing a lot of research while you're at Google, in addition to being a software engineer. But like is that kind of a common career progression? Or would you say that's relatively uncommon? Yeah, good question. It's I'd say it's quite different because like the the academia track and in particular. So I friends who have transitioned in both directions. So I friends who did a PhD in academia, you know, and published these doing research and then coming back to engineering in industry. And I also friends that have done engineering in industry and the site like, oh, I'm going to go and do research and go back to academia and do a PhD. And now some of my friends are facting members. A family industry in all the faculty. I think the, so like the motivations for doing that, there's like both like academia and engineering in the industry are very different career paths with very different incentives. In the US, especially like academia is kind of a rigid track where I expect it to like you have a very fixed career path where you're expected to do a PhD and then possibly a post doc in between. And then you know, have a junior faculty and a senior faculty. And it's a little like this is so different from from from from industry and for my friends who've done it like the move from engineering in the academia, I think a lot of the motivation is don't want to do research like they wanted to, you know, really like advances that can feel. For me, the motivation was a little different because like I, I'm so different from from my friends in that I didn't actually go back to academia to do the academic track. So I've actually, I do not have a PhD and I've had a PhD which is like very unusual and basically, so yeah, you don't have any intention of doing a PhD. I don't, which is like, I'm literally the only person in my lab who's not like thinking about getting a PhD or already has a PhD. I, I saw think of myself more of like an engineer because like I like I like building things. So, so let's sort of a little different from what my friends motivations are because like I'm not going to be on faculty track ever basically, so I'm not going to be a professor. And the way I'm thinking about it is like instead of like my impact being polishing research, you know, like bleeding research and thinking more of my impact is being a supporter of scientific researchers. So I write software and software and I maintain infrastructure that enables other scientific researchers to do their stuff. And I think that's like, that's all like a big motivation for me. I think like I really enjoyed being close to researchers like at Google, I also had a bit of that because I work on cancer flow and there are machine learning researchers in Google and I think that's a kind of a scientific message. But I might kind of know like I feel a lot more closer to the research than advancing than my knowledge at Google. That's interesting. It's almost kind of like a data engineer role where like the way I think of data engineers is there team up the data for the data scientists right there. They're there. They're absolutely essential in getting the data scientists what they need to do their job, but the actual job is done by the, you know, like maybe a weird analogy, but like you know the pilot flying the plane that's dropping the, you know, the paratroopers during, you know, trying to reclaim the country from the Germans or something like that, right? Like like you're actually kind of like putting them in position so that they can succeed in their mission. But your skill set and the work you do is a little bit different. And of course your background is different. And your goals, as you said, the incentives are different because you're not trying to become like a tenure track, you know, professor who is already at some big research institution, but you're doing like a, you know, a more kind of like a dirty job of like looking around with the actual data and the actual sophomore. Would that be just a good one. I think I think that's exactly right. Like that's how I think a lot about like. So when I once said Google, I was working in particular that's like building machine learning infrastructure and you know researchers with you know research a lot of research is done on TensorFlow. So TensorFlow is like machine learning framework right for building models and a lot of research like machine learning research is done on that. And I saw a steam my job as like working like I really enjoy working with infrastructure like building things for all the people to use and solve like my transition is kind of like you know instead of building things for industry views I'm building things for for academic researchers to use and you know I'll open source users as well not just people Stanford. So I kind of like I mean I see I really enjoy being this kind of like you know build things for for research users because they have lots of like interesting ideas and enabling them and like enabling this ideas and like re-talking to them and like learning a use case that's like really fun and enjoyable and like I saw the discovery of like doing that and I also do really like like in industry you know less times or smart people doing this stuff. So my my current job goal is my job position is called research engineer or in some other universities because research software engineer. So these are essentially programmers who help help researchers accomplish research right either by building infrastructure being software. So of applying the practice of software engineering to do research because like researchers themselves might not be software engineers they might not be aware of like the best practices of engineering even basic stuff like you know how do you build production systems how do you build how do you use code control how do you do monitoring these kinds of this skillset is all of like things that familiar to engineers but must just familiar to researchers. And those those sort of like a lack of good engineering I think in in research context and in some cases like you can really a salary I think research can really be a salary that you know if more software engineers just well on this on track and like really you know once it's been as well. Can you give me some concrete examples like like maybe like something you've noticed where like oh researchers have been doing this but like in industry for years we've been doing this superior thing and now I'm like kind of bringing this fire down from the gods to the researchers so that they could you know cook their chicken more effectively so to speak. Yeah I mean I have some really incredibly basic examples that you're actually fine and I do absolutely basic but my next examples when I so when I first joined this organization there was sort of like getting ready to push out this initial paper for how holistic fellow creation of language models and they were trying to essentially like they had a front end that visualized you know the results of benchmarks and more those they had this UI that showed here all the scores that the model sketch here will be quest presented the models and the responses from those models and when I looked at it it will literally loading hundreds of megabytes of JSON files into the Chrome browser into your web browser for page load you know it's crashing the browser. Wow they were doing this what are they doing this through browser? Yeah because this this they were building the UI for viewing the results in it was a web app right for viewing the results but they didn't do any some of any from like filtering of page nation so they were just like verï¿½nuring this giant web pages that you know that like would make a call to fetch hundreds of JSON files and then render this message HTML dorm tree that would just like eat a volume memory and crash a browser and I hope so like basically a very basic web development stuff so like further on in the life cycle this project we had a few volunteers we actually had a volunteer from outside Stanford help us port things to react and that made like everything worked so much better like the web app was so much faster it was so much easier to maintain so this was like I'm not going to pin credit for it like it helped out a bit this was mostly one of my master students, Fazon and a extent of contribute to who helped work on that yeah so essentially it's just taking kind of like a lot of fundamental you know know how that you've built up working at you know you worked at Corsair you worked at Google you worked at like a lot of big tech companies in Silicon Valley with like lots of best practices and kind of like a lot of methodology and like like there like codes metals and things like that you probably picked up and one of them might be you know having pagination and loading too much into the browser so you were able to kind of like there was a lot of perennial low hanging fruit that you could grab that yeah accessible but people didn't know to reach up and grab it yeah I think more like maybe last trivia or last last trivia examples for instance things like how do you do continuous integration right and how do how do task code and make it you know keep it working while you change it things like what technology you're used like my colleague at Stanford they were all also research engineer and he used the ray framework for this this three that that I put pre processing for machine learning models so as there's like you know you have a problem what kind of technology itself appropriate yeah things like yeah things like I mean a lot of these are like so code practices like even things like Python type of machine right making your code so that you can install it from pitch like that's something a lot of researchers like don't bother doing because it's tricky also a lot of this like some of this work I would say that like some of these work has to do it incentive alignment as well because as a researcher job is solved to put our papers because that's that's what they're mentioned by right and it's not necessarily to put up good software so if you look at the code that's written like for papers they might not be easily usable by another person so another researcher externally in my look at your code and they might take hours together to work or they might have to reimplement itself it might not be a pip install like Python, pip installs of situation and in many cases like the researchers they do know how to do it but they don't have the time to because they're busy writing papers and like creating you know easy to use software to not pile up the incentive structure yeah I mean if you all you're measuring is the research output and you're you're not measuring the hidden cost of people who are trying to reproduce your work having to like deal with spaghetti code basis and stuff like that and get things running then like hey my job here is done and you walk away from this rigour moral master app and you know yes you're you've got some additional citations and your you know the department chairs happy with you and you're going to be able to hopefully secure funds for more research and all that like that those incentives the researchers face and I don't have any experience doing research my age number is extremely low I do have a Google scholar account but it's like just a few people have like cited like some stuff I've done but none of it was approached as a researcher it was just me trying to put public information on the public but yeah like yes that's right incentives that they face or like obviously you have a lot of peers that are researchers you've worked with these people every day it obviously Stanford is you know a very prestigious place but you can imagine a lot of research institutions that are not name brand household names what what are some of the priorities of a typical researcher and how would they differ from you know a software engineer who's trying to write you know maintainable code that'll run well yeah yeah so I work with a lot of PhD students and if you postdocs and faculty a lot of what people are matched it by is the impact of your research and we impact it's a lot of very basically defined right I like to joke that research is the of original influences because there's a measure by how many people like know of your work or familiar with your name and like a lot of researchers are just on Twitter now or I guess it's called that like literally this course happens on Twitter and I've seen people literally put screenshots of tweets in their research talks so by the way you measure impact influences also a little ambiguous and depends on the specific field so I was mentioning earlier like software artifacts you know most researchers don't really care about that I should clarify that it does depend a little bit on the field because like I see for instance in in AI I have seen some researchers say okay I've written a software package and it has like 10,000 stars and get hard and like you know big tech companies are using it and that's all they're the measure of impact okay like people are using my work because they're using my software so that's all of like I think that's all the shift in culture especially in the AI field where like you know if you write things software that's being used that's also considered impact but that's not necessarily true of other fields like they're some fields that you know that's not true and even within AI in the quality of research software so very a lot some packages you can just pay them start and you use some of them you know it's research spagatico that works but it's not really used about to another user so it's still very very widely let's talk about home because that's the project that you are the lead maintainer of I believe and and if I can like kind of express what this project does essentially you try to take all these different models out there like like GPT4, Claude like all these other large language models and essentially you evaluate them to see how strong they really are and I'm really interested in how you measure how good something like there's so many different ways they're standard exams you can give it the bar exam you can give it probably like there's like an established corpus of like pieces that you put it through and you have to come up with like standard metrics that you can apply and then you have to like grade these and this I'm not sure how impactful Helm is in terms of like you know a lot of these models they're they're they're marketing like they're performance on different benchmarks and they're marketing like just the overall power of their model right and and especially with like models that are like size differently like Google has like I think like three or four different sizes of Gemini and Facebook has like maybe different versions of Lama that they've put out there and and so you have to be able to make like apples to apples comparisons for like different tiers of you know models based on like how many parameters they are or what kind of hardware they can run on maybe you can talk about that like I'm just throwing a bunch of stuff and and please note that like I know nothing about what I'm talking about I'm just trying to structure a question and tee it up for you if on so you can yeah like I guess my question is what do you do so that's actually a really great intro so holistically evaluation of language models or Helm for short that's the main project that I work on and it is both a research project in the sense that it has published papers it has a paper by the same title Helm which has a like more than 50 courses on it and it also it also encompasses this open source framework that you can use to reproduce a results or you can actually use to evaluate you know your own models or using own datasets so it's actually what we do is we this framework has integrations with a lot of different models and a lot of existing benchmarks so a benchmark is you yourself mentioned is earlier about a benchmark might be something like oh give the model you know questions from the law exam or from academic exam so for instance a popular benchmark that people talk about a lot is MMLU massive multi task language understanding or MMLU for short and that's literally academic exams from high school level and university level from across and about different subjects and you give those multiple choice questions to the language model and you see if it can get the right so what Helm does is we've picked a lot of these existing benchmarks and most of these benchmarks are like you know they are existing papers from the literature so they have been peer reviewed they're finished service for a while and what of them we've talked collected them into a meta benchmark and we've taken so this style of papers or benchmarks that we've decided on and the style of models and we've basically evaluated every model on every benchmark and we do this in a way that is standardized and comparable and also transparent so you can go see like exactly all the requests you know the exact raw request that we send to each model and all the raw response we get back and from each of these you know these benchmarks and models we compute some metric number and that you know we build a table of all these numbers and that is we call that the Helm leaderboard and if we go on the Helm website that's what you see and you know like that like certain model developers have used that from marketing they say oh yeah you know we get so and so the Helm leaderboard so yeah the open source software palette is like you know people want to do these their own evaluation so they want to know okay if I have a new use case like let's say I'm trying to say use a model in a medical application or something and I happen medical you know data set a benchmark you can go to Helm and say okay run this model on my benchmark or if you have your model you can say okay you know try my new model with this benchmark I can use that for comparisons that you can use this to run like model evaluations okay awesome and I'm looking at that and I'm linking to that in the show notes so if you're watching this on YouTube just scroll to the description if you're listening to this in whatever part of the cast player you're click the notes and you'll be able to see a link to this and you can see it for yourself a holistic framework for evaluating foundation models and it looks like like Lama 2 is currently the winner I think the 70 B is like 70 billion parameters is that what that means? Yeah that's then that's actually from the the original paper without so the original paper we have our data version which I'll send you so you can link it but the current the current later is leaderboard I believe GPT one of the GPT variants is on the top right now GPT for variants okay awesome so yeah yeah but yeah we we benchmark the a bunch of like close source models like Open AI GPT models we have Google Gemini and Enteropic Cloud and we have some open weights models like Mishro and Meta Lama and a few more yeah yeah and for the benefit of people who are unfamiliar with like weights in the meaning the significance of that maybe you can talk just like you know LLM 101 or neural network 101 like why what weights are why it's important that you open source those as well as the model yeah yeah yeah so let me back up a bit to a language model most people are just kind of familiar with chat GPT as like as an example of a language model so a language model is a model that takes in text input like you give it instructions and then it gives you the text output like like sort of like assistant response and these models have been trained on a large amount of text like a large copy of text which usually internet text and from some other sources and when we say model like this is sort of like these are all essentially deep learning models on your network specifically they use a architecture called transformer but you can think of it like you can think of it as quite similar to other forms of like deep learning on your net models where it's a network of parameters and these parameters are trained based on the input copies so when you think of like GPT like chat GPT or Google Gemini these are typically models that you access true a company in web application or mobile application or API so essentially sending the text over the internet to the servers and your sent feedback to responses so it's essentially the running service so this contrast with what we call open weight or open source models where you are essentially running the model on your machine you control like on your laptop or your desktop and you're running it as a program and you're sending it the input and getting the output from that program a lot of the most powerful models right now close weights meaning that you know the companies do not make the model weights or parameters so I use the term weights and parameters interchangeably okay it's basically like here here the numbers in this network that you use to that you use to compute the the text output from the text input right you think of it so like a program most most of the largest models right now are the most powerful models close weights in the sense that they are only available as a service running on you know the company servers so this includes open the IGBT and traffic cloud Google Gemini this is in contrast with open weights or open source which is things like Metallama yeah to Omo, Mistro by Mistro which you can actually download these on your computer and like run them locally and you know run them like a program basically like you you give it texting put because your text output this is so significant because the close models have been so opposing a problem for the research community because we don't know a lot about them we don't know a lot about what their I go into them what the weights are we can't do experiments on the program because we don't have access to it so a lot of the work like a lot of the discussing academia is like how do we you know how do we get more open models that we can run experiments on and how do we get them to be as good as the close ones because right now there's a big gap between the open and close models yeah and how big is that gap and is it narrowing the gap seems to be that the gap is never significantly because of one a couple specific companies actually and one now mentioned is Meta which is Facebook's current company they have open source should say not open source they have released an open weights model called Lama or family of models called Lama actually the latest version is called Lama 3.2 and this is interesting because it is in model that is produced by a big tech company so they have access to a lot more data and compute than you know say the set standard university do so they have been able to use these resources to like produce this very high quality model and they're releasing it under a license that actually not open source it's actually a very weird license that has some restrictions on use so it's not considered open source in the traditional sense but because of that like that model is very similar in capabilities to the other model I mentioned earlier the close ones that include Gemini, Claude and GBT so I think that has given people a lot of hope that maybe you know close the open models can catch up the catch here is that when I say open I have been using the term open weights which is a little additional open source and it really is the high say open weights is that if you think of what this source is for model so when we say open source we usually mean that in the traditional software sense we mean that you can look at the open the source code right you can see how the program was built you can understand it you can give us engineer it and can make modifications to it and we build it in the context of machine learning and it's a question enough like what is the source code certainly it's the model code so like the code that trains and generates detects outputs but also you also need to data that train the model on knows to like create this model and meta has not released the data behind this model yeah so there's probably a lot of reasons why they won't release it because I imagine as a credible intellectual property infringement so just to be clear I'm going to we're going to talk more about this I just want to give some context so meta is Facebook like they just changed their name but it's the same you know marks like a work company or collection of companies he acquired instagram required what's up and those are like you know but he has infinity money practically he can subsidize he can build things like open weight models just speculatively because it costs like maybe like 1% of their operating budget or something to train like these models and and to release them so for them it's like good PR and and I think it's cool I'm glad they're doing it but I'm confident that if you if you actually looked at this source for all these different and they're ongoing lawsuits like the New York Times right it like all these companies are suing I think all the foundation model companies and they're probably sitting in Facebook too because just because they made it open model or open weight doesn't mean that they didn't infring upon the work but I guess what I'm trying to say is like they wouldn't put it out there as like here are all the books we stole and all the Reddit articles we scraped and all the free cocaine particles we included because we have thousands of articles that are almost certainly in these models yeah and to be clear like we don't have any ongoing lawsuits with these model makers I wish that we credit us but you know we're not gonna waste our scarce donor funds to go and try to launch some speculative lawsuit against opening out of here against you know marks are covered we don't have the money to do that but like I just want to be clear like if anybody's like oh my goodness is Quincy like in somehow endorsing the the way that these were built absolutely not that this is not like this is not a conversation about like ethics or anything like that like we're just how do you get here that's what I'm trying to ask that's why I'm trying to establish like so so please don't like read into this is like oh Quincy's tessly endorsing the theft of a whole bunch of intellectual property we were robbed too right but now that these models are out there and they are out there like let's understand how they work and you know how we can potentially use them because the genius kind of out of the bottle is the way I see it and hopefully people will be compensated maybe free-cooking and we'll get our check some day too and you know but anyway I just wanted to clarify a few things for the audience to make sure they understand so llama is like like the animal with the long neck L L A M A I think it's like they originally have an L L M or capitalized because it is really confusing because it is an L L M and it's a clever name but that's what we're talking about here yeah the cute capitalization by they changed it's analogous about the normal way yeah you might also actually accidentally be a plaintiff in one of these lawsuits because one of these is a class action where the classes or get had open source authors okay and I think the the wait it's a plaintiff for the I don't know like yeah yeah yeah yeah the defendant is a plaintiff in the eye loss yeah so opening eye is probably defending from the plaintiff which is probably get up so all look forward to getting our our check for two cents open from the mail which is like I exactly I've ran away you know you check in the past for like two or three cents from some thing I guess to pull the money you might get a free-cend donation from opening yeah yeah yeah yeah yeah and this is like this is something that all that thinks very much about like the ethics of this thing I'll say that like it's not very sad though yeah what the what the the ethics and illegal framework around this is like as you mentioned there is a lot of material going to the train there it's probably encompassed by IP rights in the lecture top the rights it's unclear if they're allowed to do this it's unclear if the copyright applies to the outputs of the models and whether those outputs can be considered to be infringing there is some as you mentioned there is some stuff going some cases going through the courts so eventually there will be a case law around this that will clarify some of this situation there's also a lot of activity in the US government around this so for instance the US copyright office has a number of listening sessions last year or this year about essentially asking artists and writers and musicians weigh in on impact of generated AI and if interesting those topics like those transcripts from the the copyright office of public and those those are great things to listen to and hear what you know people what constant people have so like personally I share many of those constants and definitely like things that we think about we think about things like you know how do we how we compensate people fairly how do we you know ensure that artists don't lose their jobs or get displaced by technology yeah so like civic aside a lot of those concerns I think that is really interesting and I want to make sure like I'm not dismissing the concerns but I just don't want to spend our scarce time together talking about those kinds of things when we give you talking about the actual technology right okay so you have done a great job of describing how these systems work and now maybe you can talk about like briefly like the process of benchmarking like how do you put these models through the paces and how do you figure out which one comes on top and I love this term win rate maybe you can describe what a win rate is yeah the win rate is actually probably the most innovative but also potentially confusing part of this benchmark so we run a bunch of different benchmarks right so we can think of how much a meta benchmark meta benchmark and the benchmark says things like academic question answering solving math questions during translation answering like domain specific questions like medical and legal questions and the win rate concept is kind of how what's the probability that this model does better than another model given that you pick a random competitive model and you pick a random benchmark so it's a way of like doing this aggregation that is um solos reflects you know all the components all the different benchmarks that goes into it and in terms of like how we do this evaluation like each benchmark is actually a little bit different so for instance um the the multiple choice crash may answering benchmark that's like easiest because like if it just asking the model hey here is a math question is the answer a b c o d you give it the question you know you prompt it with the question we are testing but and you just get a text output which is a b c o d and you just go whether it's the correct letter or not so that's so easy but it gets more tricky when you do more open end up things like say you're asking like a model for a math advice for instance which I do not recommend doing by the way in a view like context um you you get back some some some some piece of advice like a paragraph and the question is like how do you score this right so you might have to actually find a real doctor and ask them you know is this actually the correct answer you might have to have someone you might have to have like a technical reference answer that we check you know is this similar or not and there's some other techniques like for for use cases like what we call it instruction following which is like behaving like a helpful check assistant you could ask humans you know is this response helpful like I if asked it for a recipe is if you're starting recipe helpful and then then there's more recent techniques like what we call judge which is literally you ask a second model if the first model of what's happening and usually that's a pretty good job of figuring out like what humans would like interesting you know that's so interesting that you got your like standing human so you can all be a big and you're like you know kind of automating human judgment and the model probably doesn't even realize well obviously it doesn't really because it's just an alarm but like it may not even know what it's being fed is from another alarm you know like anything has some code like not hurt or something like that you know like yeah this is a benefit and this is a benefit and that's just about just doing it it's like it's a lot I mean it's a lot more skill available you can do this for like you know tens of thousands of you know millions of requests quite cheaply but on the other hand actually it's like tens of tens of thousands of thousands so on the other hand you know other researchers get suspicious they're like are you really sure that like you're measuring what this corresponds to a human's mind or is it just what like the AI over lots like one you know are you is it actually what caught the line to human values yeah that's a very interesting kind of we could delve into the philosophical questions so what what is human's actually what right because we're not talking about like a model I think you know humans like many humans are bad actors you know how much of our artistic tendencies is stuff like that and it will just maximize their own value many people will react those those economists games and they'll just take all twenty dollars for themselves and give the other people zero dollars because they just don't care they're social bad that goes like right so but but one thing one question that immediately surprised my mind when you talk about having LLM as judge I think is really you describe it does that have like a synthetic data type problem where like LLMs are creating data synthetically because they run out of like organic data that they've scraped off of reddit and and suddenly it's kind of like this this inbreeding phenomenon or something where like like genetics keep getting like miscopied or something like do you have that same kind of phenomenon when you have LLM as judge where you know biases are reinforced or you know weaknesses in models as a whole are reinforced by having LLMs judge other LLMs yeah so maybe yes and maybe that's something open question at the moment so this is small so like one fact toy is that we found some such as a found that like GPP if you have GPP you know LLMs judge it's going to slightly prefer GPP it's own outputs over the other models but that's like very human right like if you had a human judge their own writing for like five years ago they'd be like oh I'm really really like this like completely forgot they wrote it but you know they're going to feel kind of like subconsciously like this this affection the sentiment toward their own work right like everybody loves you here's our own voice everybody loves to see their own name in print right if you want to have a popular successful local newspaper in 2024 or first of all I don't think it's possible but the first role is you go right in the interview every single citizen you make sure that every week there's like an article talking about some citizens so people can read about themselves like you know yeah and so do do you start an emergent phenomenon among LMs then preferring their own work you just said it was yeah now they've seen that this behavior and I think the other part of the question is like you know you were mentioning running out of organic data so right now the LM training pipeline you start with this massive copy of text right and then there's also a face which we call post of we call it alignment or we know our LHS which is an outcome for it or post training where you essentially have humans look at model outputs and annotate them you know teach them what use to respond this and then you train them all of some more and that produces like the assistant like behavior so there's all like humans in two parts of the pipeline right the first part like the massive copies of text that ultimately comes from humans and then they did the post-tuning that's also like coming from post training that's also coming from humans yeah just to find an acronym role quickly said RL is a F reinforcement learning with human feet human yeah we're in F reinforcement learning for human feet back RLHS that's a term for human annotate this basically teach the model how to behave like a question that's being assisted in all composition that's generally giving them carrots and sticks like oh you did good here here's a carrot like here's some like exactly utility room whatever them follow instructions instruction following training um so both of these like you've been thinking like can you be both of these with you know some some model so our HF actually there is stuff a model component to in survey usually instead of using the sentences directly train the extra small model based on this preferences called we want model and use that but um I think the there's all bigger question is like how much of this can it be placed with AI and the motivation here is as they mention you're running out that uh right um that actually right which is ultimately an economic problem right like we could just pay people to write novels like hey I'm gonna give you $10,000 a month so just sit down and write it in novel a month like we could like nano readmo you know well yeah national write a novel month and then we could generate tons of work like if we just budget it so so to me in synthetic data like it's always seemed like the cheap skate kind of thing to where you know and and having model judged as LLM that just like gives me like inmates running the asylum type vibes like of course we can all say tons of money instead of having prison guards and all this stuff we just have the inmates like you know self-police and but like back and go wrong in so many different ways uh I don't know I like call me a skeptical but but like I'm like the man on the street I'm not a researcher at Stanford thinking about these things just my gut reaction is this might be a bad idea so there is um there's the question of the volume of the data and the question of the quantity of the data so in terms of volume I don't think we can get much more than this um reason is that like we're using we're really using like maths and scripts on internet this is like you know a lot of like it's a very a lot of human output right and some people say hey what if we have you know we we have private data as well which firstly is I think we have a bit sketchy and secondly I don't think that's actually the kind of data you want I don't think that they'll improve things and as there's the quality argument where people similar folks are arguing hey the trick is not just quantity is um if you just train LLM on textbooks that are written very well very high quality textbooks by very knowledgeable after all this then you get like a good model it's kind of like saying like like telling a teen you know go read books instead of like playing you know video games or something like that like have have so high quality training yeah I mean if you think about like somebody who's like playing World of Warcraft they are technically going to be reading a lot of like crash comments and stuff as they're going on a raid and there is still be exposed to a whole lot of text but I won't necessarily be high quality text high quality text yeah yeah that that's like a lot of you know that it goes into these models so like these models are learning from a lot of very you know dubious content yeah like you know astrology subreddits and stuff like that like stuff like sorry apologies to anybody who believes in astrology but um but in my humble opinion there's a lot of hogwash out there on the internet that these models are going to be exposed to and and there's a lot of set tyrical articles like for example google had the the snaffy where they were telling people though like it was okay to eat a few rocks every day or that it was okay to put glue on pizza because there were set tyrical articles about these that uh the the model was not able to discern set the the settar was lost on them and they took it earnestly so there's a lot of garbage on the internet too those better than the next and now there's gonna be a lot of synthetic data that it doesn't know is synthetic data because we've we've kind of like entered into a new era where we we've we've passed this rubicon where like I mean I could tell you like just from somebody who cares about SEO and does research and like we want free co-campus show up highly in a lot of queries and a lot of our best articles are like under LLM generated articles and it's very clear when you open it up it's just an LLM but Google's crawlers are not sophisticated enough to differentiate between LLM Slop and actual you know expertise written by some software engineer who's been working on this problem for many years who's had down in wrote like a thoughtful tutorial right uh so yeah I hope that doesn't sound like me erring grievances although I am really pissed about it to be completely blunt I think it's nonsense and it's a disservice to everybody the creators and the audience is trying to use Google to get things done and I know you're no longer a Google so don't I'm not trying to ask you to like go talking to the search oh okay that's this feature request but uh but yeah like like I guess where do we go here from here it's crazy to me that the world is not enough that like all texts ever written by humans every book every blog post everything like that's still not enough to train these models that just blows my mind that shows you how hard this problem is I guess but like we're out of text and even if we paid all bunch of people that are going to write text it wouldn't move the needle is what you're saying so so if you pay people to I think maybe like again if you're an infinite money what you could do is you could like try to like some textbooks right you could try to get like the best textbooks out there which aren't in the coffers yet and you're like oh we'll pay the publisher all the authors do you know the letters used this for training or you know maybe commission your textbooks right so that's one way you do it and if the you know if the good textbook training hypothesis is true then that might give you a better model but in terms of like raw quantity like my senses this is really all we're going to get with even like I think like maybe a year ago people like oh let's just do video right because there's tons of video out there the following is that people now are doing video like the latest models like Gemly and GP 40 are trained on video and images so they have kept on that already and the last point mentioned like the AI feedback loop problem there have been researchers who have run like so there's time for researchers with run experiments like what happens if you just try to train a small model and you know have it keep training on its own training data that they eventually go off the rails so that itself improved or does it stay the same and so far the answers it depends like there have been several people who found that that's go off the rails but there've been come the arguments that are like oh if you if you fuceted there are definitely or do the sampling differently then you can fix the problem so it's a little bit of an unnecessary question right now personally my my money is on no you can't train a L and myself forever well so in a very constrained domain like go right AlphaGo they originally had tons of training information this is my understanding I'm not a researcher I've been really quick me just correct me if I say something incorrect please but my understanding is they had a bunch of training data they had like all these gains played by like high level go players and they trained AlphaGo on that originally and then they realized oh well we can just have it play itself in computer time so like thousands of years of playing eventually it'll like discern the rules and kind of like build up from first principles how to play go really well and that was like how they did it because they didn't have enough training data or they just found that that work better for that specific use case is that is that what happened yes there's actually what happened so there's this concept called so there's firstly the database by training on original players and then there's the second part which they call a self play which is essentially you take two copies of AlphaGo and you play many copies of AlphaGo and you just play it against itself right and that gives you lots of gains and you can use that gains as training data and this all works this all works in the AlphaGo setting because goal is a game with a fixed wind condition right like you want to win basically that's a score that is a concept of winning and losing the problem we have tried to apply this to our hands is that when you're talking about a assistant the concept of winning is very unclear like what we call the you know utility how it's for this so we mentioned how the M with the judge earlier you could interiorry you know try to generate you know have try to have smaller stop with themselves at the hands of just say like these are good conversations train on these good conversations but there doesn't really work in practice because the LMS judge like like this there's so many issues is quite like but one issue is like the concept of goodness is just so identifying because like you know in in a human language context there's you know there are things like health when there's creativity like values like more more intangible things that we care about conversation that's so hard to imagine or tell like a model of health and measure and it's like that really makes it like difficult to you know try to steer models what's this you know not stop because you don't know what the not stop it yeah yeah I mean that goes for humans too like on the forum uh if you look like the free cocaine form pretty active form maybe like seven million visits a month um people just helping each other with programming questions and encouraging one another in their job search and everything like that and uh you can like heart replies and you can like even mark or replies the solution which is a lot of signal to us because we're trying to like figure out who are like the most helpful people so we can figure out who to grant moderator privileges too and things like that and so the moderators can like kind of like pick out like stars because we want to establish like top contributors of 2024 right we're going to publish that uh soon like it's probably out by the time you are uh listen to this but basically of all the open source contributors and people active in the community like we have to make judgments about who's the most helpful right and uh so that is extremely difficult for us to judge because I mean it could be the threat is on it just a really popular topic like if you go sort sack overflow uh post by number of up votes a lot of times it's just like some you big word of technology like get or a van or something like that and people have asked questions about that and because everybody's googling that and they're like oh this helps and unlike because it's a more prominent question it gets more signal in the form of up votes and then you know perhaps the most eloquent helpful answer to a more obscure question would not get similar like is there a similar consideration in judging models like if you're giving it some relatively esoteric task that it is uniquely qualified to do well over other models like do you wait that additionally like for example you said legal advice right like that is the realm of expertise people who spent their entire careers immersed in the law and understanding like all like the precedent cases and all that stuff and understanding like probably having some intuitive grasp some intuition they built up from just doing this for so many years and if you have an LLM they can give good legal advice that a lawyer would actually say oh that's pretty good you're going to wait that specific task much more than somebody who can like you know solve you know a basic you know mass problem or something like that right because like a lot of model so how do you when you're actually establishing how to rank these and you're establishing the I guess the the heuristics the rubrics for which you're evaluating these models how do you wait different types of expertise and how do you think about like models that are exceptional in a difficult area and and separate those from models that are just like generally pretty good. Yeah so this is a very complicated question and impact so firstly ultimately we want models that are so useful for people in professional settings right so for instance like right now like catchy pt is so a great compaltry tricks but there's a bit of a question like if you were a lawyer and you know in a lot of their situations like okay I want to go look at all existing case law that's related to my my current case and I want a summary of that that solves sounds like an error and task right so so like lawyers have been thinking about and research has also been thinking about like can we get it to do this and the question the answer is it solves like it depends very much on which professional domain you're talking about like law or medicine or something else and it also there's also just not a lot of like applications being used like view applications being done right now like I'm sure you've seen those those story of like some lawyers try to ask chatchvt for case law the chatchvt made up some big stuff they showed to the lawyer and I mean to the judge and and they go under control. I was afraid to look it up and it didn't exist those DIYs or whatever metric they're using were not accurate. Exactly so so there is a sense that GDT there's like a suspicion that GDT like is not ready for a lot of these real well professional tasks and what what we've been trying to do in the lab is like we've been interested in finding like specific professional use cases and trying to build benchmarks around them to see like hey no here's here's what it looks like in a real real life situation the problem is that a lot of these benchmarks going to exist right now and there are many reasons for that like firstly any professional experts to build those benchmarks and the timescars and there's secondly a lot of these data like for instance if we talk about medical benchmark it's very hard to get medical benchmarks because of privacy and data protection issues and then there's issues like there's also like the sense of I think not all the domains have equal amounts of attention on them so for instance because LMV such is done by programmers there is a lot of programming evaluations like there's a benchmark for instance which is like can you take a get up issue and like the pull request for it which is kind of a reason of professional task that the rewension they would do and I and my my suspicion is like the reason you know that's the much welcome this is because like we are we are computer science people we went to like scratch on our pitch so that's a lot of work on that yeah so the main we already know and understand because like most computer science people would probably open up a whole request before at least read a get up issue and had to think about how they would go about solving it yeah so I've heard this term called the reggae frontier of LM which is exactly this idea that the LM might not be as capable at every you know may not be capable at every subject like it might be hates or something though but it's not great in medicine or something so ultimately you kind of have to do this evaluation case by each you know use case they actually want to use it and so the ragged frontier ragged like like a torn cloth would have I mean this can be longer in certain places than it is in others there's going to be kind of maybe zigzagging pattern and so the pattern zigzagging across all these different domains of expertise and not all the the most explored is software development just by virtue of it being so close to us and by you know programmers put tons of stuff on the internet we've got like 20 plus years I think it's probably about 20 years worth of get a goot um I'm sorry stack overflow posts right at this point we've got almost 10 years worth of free co camp question and answer threats we've got like just tons of programming tutorials that have been published in video form for example and around the books and like all these other things right yeah if you look at the training data so so there are some papers that do publish you know what goes in the training data of L at hand for certain models it's a lot of programming material and some of it is exactly what you mentioned right like programmers we we live on a web so we're more inclined to share on a web there's things like like overflow which is very mature infrastructure for sharing knowledge on the web so some of it is just because there's vast quantity of programming knowledge on the web that you know that coding stuff like also all of get how cold as well that so all that you know there's a lot of programming related material that goes into L at and there's like there's all of the question of like does that you know there's a hypothesis that this is good because the programming knowledge people hypothesize that the coding teaches the model of how to do other things like mathematical reasoning or logical reasoning as well because they're such similar to give sets yeah wasn't that a big unlock for GPT4 like I remember they included like the the kept changing the name of it but it was basically like it would write code and then it would show the code that it used to come up to arrive at a conclusion so yeah it's like some sort of chain of thought yeah but actually you could actually see the code and you could look at it and that was like a huge windfall for me to like better understand how this thing was quote unquote thinking it was to be able to like okay I asked it a question like like how many airplane seats are there manufactured in the US each year and then it would go and like figure out like the plane production and stuff like that or something I don't know but um yeah yeah do you think that that is like a big part of so so by teaching it so much about programming and what I always try to think of programming what I try to communicate to people who are learning programming is really just thinking about thinking like trying to really distill your thoughts into clear instructions that can be interpreted literally by a machine it's like the highest form of precision communication possible outside of like maybe like law right laws literally called code right because it's like if this then that right and and that kind of like logic that essentially runs entire nation states and and similarly code like if you look at the Linux kernel if you receive this type of input you know return this or call this function which will figure out what to pass back to this or and that might call several other functions and it's like this hierarchy almost like and it's somewhat deterministic and and so by thinking like your programming it forces a certain rigor to your thinking and I can see how that be very useful to force the all and to explain itself in similar uh on a similar level of uh clear yeah i've actually heard a lawyer describe um law as code programming code before do I think that's also not like like necessary to because like in you know in humans as humans we do a lot of ambiguity and one of the things out of them is a quite bad at right now is dealing with ambiguity like doing ambiguous questions so recognizing ambiguous questions so that's that's kind of interesting but I'm like I do agree like I've heard like the reason you teach code you know like it's not like a big benefit of teaching coding to students it's just having them gain that mathematical reasoning or that logical you know the reasoning skills yeah it does teach you like there's the famous Steve job code everybody should learn how to you know program because it teaches you how to think right of course famously Steve jobs didn't know how to program so you need to take his own advice but but you could definitely extend that to everybody should learn how to program because it teaches you you know critical thinking logic and importantly it teaches you communication skills I think like that's been a huge unlock for me the precision when I started to hang in at with programmers I was used to teach and you know hanging out with teachers and stuff and like the level of specificity if you use a phrase like casually oh what was it matter of fact I did oh is that a matter of fact you know like you know like you would ask this question oh hmm I'm not sure if it's actually factual that that is the case you know and like like all these like little kind of like things that we use in English are extremely in precise but humans are extremely good at interpreting ambiguity and like the human brain seems to be structured very well to differentiate like a twig on the ground from like a snake and things like that right whereas you know computer might see that shade and they may mislabel it or they may mislabel you know muffins as qawas and vice versa and stuff like that right so yeah obviously that like that is improved a lot but but that just goes to show that like humans have so much sophistication in their perception and it's going to be an extremely long road to get computers to be able to have that flexibility that the human brain shows. Yeah definitely I think a lot of this early work like if if you look at how a lot of the evaluations we do a lot of early evaluations are just things like can you ask and some of which are questions right and that's very different from can you hold a long conversation with a person is like so much to do with you know like I mean talk about ambiguity but there's so much more skills as well involved in that right and yeah I think things just a long way to go there's some people working on this social aspect this more like do do LMS have social skills or social intelligence can they reason about people can they like you know can they the sweet people can they understand emotions can they understand puns and humor and that is very much open question right now. Yeah and so I have so many questions to ask about the capabilities of all of them because I think they're probably both overstated and understated in various you know public reports and stuff like like in the media and stuff like that what are some of the most impressive things that you've seen an LLM do over the past six months or so. Wow that's a difficult question. Both interesting. So the I thought my sense of impression is as a little skewed right now because just like hanging around okay I can give you an example so there's a famous mathematician, Terrence Cow and recently he was basically given a preview access to a opening item model called O1 and O1 is a model that does chain of talk reasoning so he mentioned earlier chain of talk reasoning is when the model is you ask in a map question instead of just giving you a short answer it's going to try to like generate a few you know a section of text that is like reasoning about the question before I figure out what the answer is so so he was given this model experiment with and he basically gave the model a few like ask it to he asked it to help him with very high level proofs like he asked it to translate one of the proofs into it here I'm proving language she asked it to write another proof one other problem and he he actually enough saying like okay this model behaves at the level of a mediocre grad student and the internet was kind of like internet response was like wait how are the goal post moves so that like 10 years ago if a model was able to write a a graduate level proof you know that would be amazing but now we are like oh it's a mediocre graduate student that's that's not impressive anymore somehow so I think that I think that was a pretty impressive demonstration like the fact that you can actually use it for high level you know research mathematics and it actually produces some value yeah I mean I use them all the time and I continue to be impressed with them like just yesterday I was like I took like a giant PDF that we created years ago and I don't want to go through in many other like convert this PDF into JSON like it the properties back out I can't find the original properties I used to generate the PDF and I just said hey figure out like I gave it to TPD40 and I was like figure out how like what the structure data is in this PDF it's like you know 10 pages long and turn it into JSON that I can use for a rest API and it did it it did it well I did I did fix things yeah it means just incredible times it's nothing that I couldn't personally do I could probably do a lot better job than it did but it's like having my own mediocre grad student who's doing my exact bidding and yeah I don't have to call somebody wake somebody up right I just jump in there and and nobody's really in convenience open AI spends you know dollar or something running my tasks and you know I just got what I needed to get done done I was talking with the guys from the change log yesterday the the host of the change log the big open source podcast and they said that they think that LMS have made them 20 percent more productive as developers and I mean if you think about it 20 percent more productive that's a huge change in productivity like not since like spreadsheets and you know scripting languages or I'm trying to think of the fundamental changes maybe Google search that have unlocked that amount of productivity so it is a massive change in productivity but what I want to ask you do you think this is just the beginning or do you think 20 percent is like good enough to justify the evaluation of Nvidia and like all these other you know all the investment in the space I mean do you think that this is just the opening volley of the productivity that's going to be unlocked by these tools or do you think we've already kind of gotten a lot of the initial benefit and there's going to be you know ace up asymptotically diminishing like returns going from here yeah unfortunately I may I skeptic actually okay I would bet on busy like I think that's the extra question of like you're mentioning that there's like literally hundreds of billions of investments that has gone into to a high tens if not hundreds so like there's a little there's a question of like is that are we going to get tens or hundreds of billions of returns and I think that I don't know I'm not really confident enough in either direction the thing that I I'm fairly confident about is that the pace is sort of slowing down so the reason for that is that if you look at recent model releases the pace of model releases has and hasn't really kept that like there was GPT tree and then GPT four after a year and we're like oh maybe GPT five is now but you know GPT five hasn't come out there's rumors that you know the data question I was asking I was talking about earlier like that's not the biggest question there's you know some people think that maybe if we completely change the way we build the model like if we use a completely different architecture we can you know do another step have another step game where we jump from here to something yet but that's that's very difficult to predict I think there's really a lot of people working on new architectures and new techniques but it's very difficult to predict if one of them will be bad for it it is difficult to predict but like let me ask you to make a prediction so we've had AI winners like all the way back to the like the 1950s and stuff like oh this is nobody deal soft for it's easy like that that's what they thought back at the time and like we've already got these these you know computers and stuff like we can do anything we can simulate like a human brain no no problem like greatly underestimated the amount of work and you know then there were like little high cycles you know like bubbles up of funding where suddenly AI was the big thing and then it died down and like maybe over 10 years or so I don't know the exact interval but it was a pretty predictable kind of sine wave of interest and maybe it was more like a saw wave but now more than ever we've got tons of interest we've got tons of money we've got tons of very smart people like you working on AI either working on AI at you know Google before you started working at Stanford Researching AI and trying to evaluate AI through your benchmarks now that we have so much attention on this do you think that that dramatically increases the rate at which we're going to develop things do you think like that we would have to put in in hours of research you know and maybe the collective amount of research put into AI over the past 50 years is the equivalent of what was put into research in you know 2023 or something right like do you think that now because there's so much attention we are going to get those gains faster or do you think there's like other limiting factors besides people thinking really hard about this stuff just we just need more passage of time I'm yeah I don't really know I mean certainly the amount of investment into AI is increased by and even like researchers like the like at Stanford you can see a lot of research basically a lot of researchers are working on large language models right now who weren't before I am actually not entirely sure that's a good thing because if you if people go into our research like a lot of them are coming from someone else like another discipline of AI or another discipline in a computer science and that's not necessarily like my concern here is that like okay what's going to happen to those fields like that that have fewer researchers and I think the other thing is like I don't know I don't know at what point you get diminishing returns because I certainly there's like a lot of people trying a lot of interesting new ideas in parallel but I don't know at what point like how how confident I am that one of those ideas really allows to like surpass these fundamental problems yeah in a lot of science fiction obviously science fiction written before yeah I so like one of my favorite series the expanse the authors talk a lot about how AI is everywhere but it's just kind of invisible and it's doing little things in the background and making life easier and simpler and allowing humans to make the higher level decisions but it's not like there's some overlord AI that's making all the decisions and you know that the president and AI and all this stuff right so it's clear that like in at least in that universe that they thought of which is arguably like the most scientifically accurate like science fiction series ever other than maybe like authors who call our cursor on the link that but it'll look very accurate right so those people who are not AI researchers I don't think they're like software engineers but they didn't think that AI would you know become this huge thing and they they clearly thought that there were like limits to what an AI could do compared to human civilization making decisions the way that human civilizations have made decisions for you know 100,000 years in small tribes and now as nation states and things like that do you think that it's possible that that is the future and that even with all the hype and all the breakthrough that we're experiencing right now we just experienced like like not a one time step but a relatively infrequent step change and we just have more step changes over the next three decades to look forward to and that this is not going to fundamentally change everything like a lot of you know people who are paid to say it's going to change everything keeps saying yeah I mean that's that's so interesting because like for one hand I argue that we saw a lot kind of already they've been that reality in some sense and in some sense we don't there are a lot of things in daily life that's basically AI and we don't think of it as AI like generally when something works so well we start thinking of it as AI like for instance email spam filters is AI but we don't think of that as AI and things like so I'm thinking talking more in the sense of like traditional traditional AI or traditional in the sense of like not error and not generated in the end. Yeah I mean some of these as used that as the common model is not necessarily you know decision trees which is if that's the thing. Yeah I was just like I really was just basically like some program or hard coding if else logic you know but yeah so in some sense like I feel like for instance money is such cool that uses AI in some sense as well that we don't think of that so we kind of like in some sense you can't really like we interact with AI every day like if you use Facebook and you use you know the algorithms decides what holds you get to look at and that's not like some of AI so like I don't think necessarily that all these applications are AI positive like for instance like you like we are solved in this reckoning moment now where we are starting to think about the impact of social media on society and the recommendation of Godson's is a part of that so in some sense maybe if in that world and in another sense like AI is very unevenly applied right now because like certainly if you use a technology you can use by a big tech company like use a product like android for instance google is going to have lot of money you know they have AI infused in all the products because they have the infrastructure resources to do that but if you're talking about you know lots of different domains that's different applications so for instance one application I learned about recently is weather forecasting google just produced a machine where the forecasting model that uses AI in a specific way that outperforms like traditional forecasting methods and you know that's a big deal you know yeah yeah there's also the thing right there's like a lot of fields where potentially you could use AI but like it hasn't been done yet for you know some for various reasons like maybe the technical barriers maybe the social political cultural barriers maybe there might be genuine reasons why you don't want to use AI right there might be like legitimate reasons but it also might be a resource in trouble like you know no one has like in there's no machine learning person in your in your weather forecasting office right since my B.O.E.s.n so I think there's a lot of like many domains where AI could be applied to a lot of social good where it hasn't really been done yet yeah so the future is already here but it's just not evenly distributed exactly I imagine over the coming decades there are going to be lots of small companies maybe solo developers who take a lot of that a promethian fire you know to trucking companies and to you know farms and to all this other industry you know and and essentially make it marginally more efficient or maybe dramatically more efficient dramatically importantly output maybe it's possible that like with you know there was a period with chess where having a human player and an AI together it was more powerful now it's just the eyes got the absolute advantage but there might be a period where humans and robots are working like kind of entanglement to get things done better or to have better outcomes like as the case with weather reports I can just throw out a wild guess and get on TV dressed up in a suit and talk about the weather and be wrong and maybe that's good enough for like a lot of people that are just staring glancing in the weather trying to figure out if they need to get a number of things like that big of deal but when it comes to you know like estimating you know like how many birthday effects a certain chemicals in the cause just like that could be like dramatically more high stakes right and and so maybe the quality of those decisions is dramatically you know it's not just a question of quantity it's also a question of quality of output in a lot of cases and so anyway I'm kind of like rambling but I'm just like trying to process what you said in the sense that we're going to be able to take a lot of the technology that we already have that may not be super sexy or exciting for people like you not even for me necessarily as just a software engineer who like kind of like reads about this stuff on you know and hears about it at dinner parties and stuff but for you know some farmer in Omaha who's trying to or maybe a ranch or who's trying to like have more better organic beef or something like that like maybe there will be some huge on locks around the corner that it's technology is already like a year or two old that they just haven't yet you know received in a package form that they can use which could just be a something like some bobble app that tells them when to like feed their cows or something I don't know I know nothing of the domain of farming so we're ranching so I apologize to any farmers or ranchers listening to this we were like tearing out their hair like what's he got us all wrong that's not how we roll you know but but my point is there will be a whole lot of domain expert experts who pick up more generic tools and then adapt them to their domain and then sell them to people in their field so that is a huge opportunity regardless of whether AI continues to improve the step change we've had is already is just going to take years for us to figure out how to use like even if you froze development and like just GPD 40 what I use every day that was like just that was how good it was and it stayed that good hopefully it doesn't get worse like Google search seems to be getting worse so I know you know you're not an other interesting about how quick of letting my Google but like ideally like it just stays the same right and it's it's not like welcome to Costco I love you like trying to get product placement or something in there but it's actually you know just it's stable us even that tool as it is is incredibly useful and I could see that dramatically improving my productivity over the next few years as I just learned new ways of leveraging those tools so I'm extremely optimistic about AI how do you feel? I'm so excited and scared like okay yeah okay not excited let's get last language models they have a potential for a lot of misuse and a lot of potential harms so I mean I can give example of a few so for instance in hell one of the recent projects we did is we basically said oh can you you know can you use a large language model to produce harmful outputs we have for outputs might be instructions on how to build a bomb it might be generate you know it might be things like political disinformation that you can post on social media so we had this evaluation this benchmark that was essentially we sent you know a model a lot of requests for these outputs and we measured you know how much of how often do these models give you the harmful output and the answer is actually quite frequently depending on the model so some models are valid in others I'd say that overall we were quite impressed by the amount of safety tuning that the developers were able to do but regardless of the model we still found and safe outputs so I think I'm very so I'm so worried about all these potential harms in terms of this information and there are also things like bias and fairness the idea that models might be biased against certain groups of people or might not work as well for certain groups of people there's also I think concern about labor displacement like if if models can take over the jobs of people that's that mean massive job loss and economists I split on this actually because like they also argue that I create lots of jobs so it's possible that there'll be a structure shift but overall you know workers turn out okay but like the problem is the education there probably I need some more education yeah yeah yeah and go to free you don't go we got your if you're worried about getting this place if you're worried about getting this place just keep learning skills and keep climbing and the rising tide will stay below you and you'll be okay as long as you keep learning I just want to reassure people I've seen nothing to convince me that like work as we know it is just going to completely go away I think a lot of that hyperbole is pushed by people who have an agenda I don't think it's practical argument that we're going to have some you know as if something like and just do better than humans absolutely and everything and that human labor is just no longer needed we're all going to be rounded up and put in these you know beige buildings and we're going to you know eat food and like basically live dairy lives while a bunch of really wealthy people just have the rest of the world to themselves and they have a zhren or ubi um slums and stuff like that right I don't so I'm definitely like legitimately processing what you're saying but at the same time I do want to kind of like push back with like I don't think it's all doom and gloom like let's talk about Singapore so you're from Singapore right one of the most advanced countries in the world I think it's like the third highest income level in the world and the other two higher ones are like wheels trust one countries yeah the life expectancy it's one of the highest that's like what we like to say I talked with Josephine teo um Josephine teo yeah I talked with her and and one of the things she said that was really interesting is Singaporeans like technically kind of almost have like a negative unemployment rate if you want to think about it in that sense that they're like more jobs out there than there are people that can do the work and so it's just a question of taking those people and giving the like skills so they can do the better jobs that are open and when I want to say better I mean like you know higher income like you could argue that like you can make a lot of money as a coal miner but it's not a good job right yeah nobody would argue that being a coal miner is a good job because you're damaging your health you're putting your body at risk it's back breaking labor it's not very much fun I would imagine going down into a dark cave and like chipping away at the walls and stuff like you can teach a coal miner how to you know working a factory or do do some sort of like slightly less dangerous slightly higher paid type job and you can level people up you could you could say that like you could train somebody who is you know a field medic in the military to they could you can send them medical school and they could become a physician right you can always like level people up a little bit and I think with Singapore because they're actually trying to train people and get more people to become AI engineers which are essentially software engineers who know how to leverage models and leverage these AI tools that are coming out with each passing month so in a way like even with technology improving and jobs getting automated the way and jobs getting offshore to stuff and like in the US employment has stayed relatively stable and you could argue like oh people are just getting discouraged and they're living in their mom's basement like this is the stereotype they're living in their mom's basement and they're just given up on getting a job and they're just playing Call of Duty all day right like that's what happened and and they're just you know but if you actually look at the numbers of people employed it's been fairly stable despite all the technological revolutions that have taken place in the United States you know system industrial revolution like all all the computers and like the information age all that stuff right and I have reason to be optimistic that this age will be similar and that it's going to take everybody and improve their productivity 20% and the the sixth person who gets displaced by the 20% well they're going to find some better job and they're going to keep climbing too and I think my argument is as long as everybody's getting smarter and more capable of stuff like that we should be able to figure out new things for these people to do and I think the main reasons for unemployment and suffering and stuff like that is failure of imagination among the people that create the jobs and and like terrible hiring practices like an African tracking systems and like you know this coffee and ask employment system and and then our resistance to it and our us trying to hold on to old steel worker jobs and things like that when those jobs were never good jobs they were all always miserable terrible dangerous jobs noisy hazardous your health and most people would be better off and probably happier working in a cubicle somewhere or working from home doing like remote work then they would be smelting iron and being around all that heat noise like that is my my theory so we're thinking that please shoot that down please poke as many holes in that please please make me sound like like a hopeless romantic yeah so actually I want to share a story from the conference that we both went to where we met the one about a startup founder who was presenting a project that was building robots with arms so this this startup was building robots that could tend to strawberry plants and pick strawberries and they were working with arms a farm in what's in view on Montrey which is a few hours south of San Francisco and like when I heard of this at first I was very skeptical I was like isn't this just going to like make lives worse for farm workers right because you just placed family jobs but the story was they were they were running this prototype in the strawberry fields and your family kids would be very curious and they would actually ask and go out to the engineers and ask them questions and when they heard what they were doing the the family kids were like wow this is amazing when can we get this and it turned out they were saying that the job of picking strawberries was less desirable compared to some other farm worker jobs and they would actually like for the last desirable jobs to be automated way so in that sense I think like I mean this sort of heights into how the thing for like Singapore thinks about about automation like instead of thinking of displacement we think about augmentation so the idea that instead of the technology replacing you you are using the technology to be a higher productivity worker you're working you know you're deploying technology working alongside the technology which of course has a lot of few activists that you need to understand you know the technology and you know the policies your workplace and government policies have to be favorable so I kind of think of this like like I think there's a lot of potential for AI to augment humans and stuff with placing humans but I think the big questions are like who ultimately gets to decide you know how the technology gets used so it's sort of like a power argument where it's like do the workers decide or the unions or the company so the big tech companies or the government and where does the power we say and how do these decisions ultimately get me so it's a very much a question of politics and democracy and economic structure I think and I think what I worry about most is like the power is still concentrated in big tech especially you know in terms of money and in terms of you know them having the models like big tech has the large language models back now the best ones like you know much of this societal transformation will be on the terms of those large tech companies and large large companies in America in general versus you know workers unions government and the average citizen and don't really have a chance to do that yeah well let's let's say I have a medically open source or open models not open source models as you pointed out open weight models they come to approach the performance on helm benchmarks and you know in all the ways that matter they come to be comparable and that free co-camp can just host to some of the alliances which we do we use it internally for lots of things yeah and every organization like a farmer can just have a box at home and can host you know the minstrel or whatever they want right in fact I've seen lots of videos of people doing this just having their own insist running that they can interact with and not having to pay for opening eye you know like I said like pros like 20 bucks a month it's not that much money considering all the uses is obviously a major that price doesn't go up but let's say have a medically those models approach and then like the how would that affect that power dynamic if people weren't beholden to the giant tech companies if like let's say hypothetical okay two things happen first the the open weight models become almost as good and then the the top of the line models start to plateau right they they do hit some sort of ceiling for performance at which point like kind of like iPhone nobody cares about the new iPhone nobody cares about the new PlayStation because it's been good enough for years and these marginal improvements in graphics or you know speed or anything are like imperceptible to the typical person we don't care right like I don't care genuinely the difference between like a $200 can opener and a $1 can opener right it just obeys the can and it works right like like what if it becomes completely commoditized and it completely platos and it's just this new tool that we have just like spreadsheets I'm sure Excel is better than Google Sheets and has lots more features but I can't be bothered to install it and pay a bunch of money for a license stuff when I can just use Google Sheets right like what if it gets to that point where all AI is is just this thing it's kind of like a solve problem yeah I think do in terms of impacting the labor market yeah I think I'm a little bit more optimistic about the future than I was a year ago so so the about a year ago like the situation was kind of like you had to pay off any I do use these models right or you use inferior models and even if you wanted to use the inferior open weights models you would need a very expensive desktop machine that would cost $1,000 or tens of thousands of dollars like all of a reach of like the average programmer right like so you thought think about you know if you think about this as another tool like a program tool when I was a teenager and if I was going to programing my first tools with things like Q-based day or PHP or open source tools that could download for free and use like and the fact that you need a very large GPU or API API is it's all like makes it so it's not free and it's all of reach for at least some people I'm a bit more optimistic that like it's gonna be more accessible because what happened over the last year is the small models got better so now we have models that you can run on your audio like MacBook for instance or on a small laptop and they work the nodes great as as GPT but they work reasonably well so I think like I'm a bit more confident now that this technology would be a bit more evenly distributed so like as I mentioned earlier there's still a gap so you know like we at Stanford we're trying to train our model as well we're trying to close the gap the other researchers trying to close the gap so that might come to pass um the one thing I'd still be pessimistic about is like even even if you have a tool even if you solve like the access of the tool and you know the openness of the tool let's do the question of like pull the sights to get you know how the tool is used so for instance like well we gave for an example like let's say employer decides to replace okay this is a very made up hypothetical but let's say employer decides to like fire all the power league as we place them with open softs model it is a still a question of power like who how did this decision get made like the fact that the tool is open soft doesn't you know reduce the harm to the power league also to fire and then a more concrete example that I just learned about is like for instance the state of Nevada is the pattern with Google to try to use LAMs to process unemployment benefits claims and this is freaking a lot of people out because there is yeah I mean lots of makes a mistake and you don't get your own employment exactly so this is like a really high stakes high risk deployment and I I can't say very very concerned about how things can potentially go wrong so I think you know this is the other question they're like who gets to the sight right they're just there in the valley you know like how how policies mean how how the policies you know what kind of these uses I love the policy so so here's my thing on this if you're interested in hearing my thinking my another really naive thinking I don't want anybody to think like Quincy's just spent hours and hours philosophizing and like writing treaties about this stuff like that but like in theory let's say that you know a whole bunch of false negatives happen or a bunch of false positives or like I mean I'm sure Nevada's gonna encourage the LM and probably curse Google can you make it deny more claims you know like that they have every instead of to do that but like is that really any different from just telling like their human evaluators like hey try to find every single little loophole you can to deny people claims like insurance companies do that all the time right like yeah you can definitely say it's even worse then what it's always been but hasn't been just like the progression of evil in society and is a I actually accelerating anything or is it just making it a little like cleansing their consciousness a little bit because it's not some human who has to push the electric shock button but it's like a machine that determines to push it right you're like a few steps removed as a programmer who's just building the doomsday machine as opposed to somebody who's actually going out in like executing people directly on a fire and you know I mean so yeah yeah go ahead the milk like like I mean people are making that that counter-acumen exactly to counter-acumen so for instance there's research showing that for instance like anyone who makes a decision in in judiciary or like in a government office they're not three of biases right there was still there was still make decisions based on bias sometimes unfair decisions sometimes incorrect decisions and now the the objective for AI some people argue is not you know to be perfect but just simply to be better or less biased or less incorrect than the human based mind I think I think to some extent extend that might be possible but it's like it's very difficult right I feel like in academia and in research resolve understanding on sets of like hey you know how do you measure these things how do you measure fairness and bias and you know accuracy but really the worry is like how in the real world how often do people care about these how often do people get it right so definitely don't know what to do it right I think but it's very difficult yeah and I just want to be clear that like I think these companies should like these giant you know entities that have lots of money should err on the side of trusting people that are filing on employment claims people that like I understand I just watched this great movie from like the 1940s called double in down any and it's all about like insurance scamming basically like but it's from 1940s it's like this in war movies very very good movie you don't want to really old movie particularly public domain but yeah I understand that there are people arguing to try to cheat in like fudge numbers and you know there's this great movie called blue collar that I watched from the 70s where the the main character he's Richard prior he's he's pretending he has six kids instead of three so that he can get like additional child benefits in his tag and tax deduction and stuff like that and that's like a major plot point and like I understand but like these are often extremely destitute people and I feel like we just need to fundamentally figure out how we don't have to put them in situations where they might feel pressured and also you know it's kind of like that like a whole principle like you know you should it's much better to like free like 10 guilty men than to falsely execute one who was innocent or something like that right and it goes back to the foundations of kind of modern or like Western philosophical thought you know so so so so my thing is like a lot of this stuff is human problems and AI is merely the weapon that the human is pointing at the destitute person as opposed to yeah so so I definitely understand that that is a huge drawback is it's going to give people like the illusion of like a clear consciousness when they're just as complicit and denying people sustenance and things like that that is a really big issue to get into and it's beyond the scope of this podcast but I did one away in and give you a give what you said proper gravity because that is very dangerous especially with insurance companies especially with like you know the area that it hits home most for me is as a as a teacher seeing these people who were mislabeled as plagiarists by some AI that can't even accurate like people are out there selling tools that purport to be able to detect plagiarism but are very bad at it and you know you can copy something from GPT open in the Winston's GPT you can paste it in and you say hey GPT most sophisticated LLLM in the world do you think this was generated by LLM and it may not know right like do you know anything about this like if you say most of the GPT is zero that's like LLM detection they're mostly they're mostly not great yeah a few tools that yeah I'll say that they're mostly not great but like now they mostly unsolved problems so any style of that's like I have a perfect LLM detection tool is probably lying yeah but there's some CIO on the golf course one one of their salespeople right now I guarantee you school systems are buying plagiarism detection and that is just the progression of evil that is just new to the capitalist the wheel turning and people going out and following their incentives to like start a company and do enterprise sales and stuff like that and convince people like hey I can save you all this time and energy that these teachers were spending trying to figure out whether a paper was plagiarized right and yeah so I don't think technology introduces completely novel horrors I think it's just kind of like a continuation of horrors that like these plagiarism tracking software is turning it in and stuff like that it's been around for a decade at this point and and it hasn't always been accurate and there's been a high number of false positives and I think it's going to get worse because there's the false confidence that these tools work you know better than that yeah I think that's that's all right I mean I'm not feeling like it's the conversation I want to be interviewing you but I just felt like like pointing that out yeah I mean I'm like think I'm scared of a lot of the same things as well like you mean earlier we're going we're talking about you know the large amount of investment in AI and a lot of this is like C-suite executives like not really understanding what the technology can do and you're not yet it and you mentioned you know this this doesn't feel like a technology problem it feels like a human problem and that's exactly right like I can to do my spirit like my other organization I work for as court uh he sent it for human-centered artificial intelligence and a lot of the researchers in who work at the center are collaborate with us are from other disciplines like law or policy or economics or business or other fields and a lot of it is exactly because like they're least funny ethical questions that you really need you know some of these like fundamental Western philosophy questions like like what's ethics like what's their ethical model should models be ethical like um so yeah I think there's a lot of interesting what there maybe of less interest to like programmers but like if anyone's interested in reading on you know the ethics in philosophy of AI there's really a which which for you that's like of next being relevant right now is there any text or you know article something that is relatively layperson accessible and doesn't have all bunch of citations everywhere like that's something that you recommend to people to get started I mean I can teach my employer has a block so human sensitive AI center has a block it's cost-spinfitCI that has a pretty good um around that off you know a lot of the societal issues um for best for a book I don't think that's specific when that I recommend yeah like they're a bunch coming out or that I've been published recently I have not had a time to look at them unfortunately awesome well um yeah if you're listening to this after publication date and uh EFON has reached out to me with a book recommendation I'm going to include it below um EFON we've covered so much ground uh it's been an absolute blast talking with you I feel like we could talk for hours but I want to respect your time you're a busy person out there getting things done researching these models like not just mindlessly kind of oh this is a higher value than this like you're actually thinking about the implications these is clear that you are among those who think and feel and that you do care you you have a big stake in the future of what society is going to be like with these models running around uh do you have any closing thoughts or or things that you would encourage listeners to think about um especially for free quote camera listeners I feel like you know you're a little talking about the job this placement thing I feel like um like there's this narrative of like you know LM replacing jobs replacing program as in particular I feel like in terms of like especially in terms of like three-to-can the students out say like even if you want to get into AI there's always a value in you know having good software fundamentals, software engineering fundamentals programming fundamentals really understanding like defundations of AI which include things like probability and statistics and I think with those fundamentals like that will carry you barefoot especially because like when when I first um so when I first joined stand that when I joined step first research engineer and I had to like pick up a lot of knowledge about LM because when I was in school doing my batches and masters LM students exist right I had to pick up these technologies because I already had to find the mentors I could like pick up fairly quickly and be like oh here's you know how this new technology relates to the knowledge already have so I would say like honestly having having good software engineering fundamentals being able to understand problems being able to what improve other people well these are all excuse that I'm gonna be the most important no matter like what technology comes next yeah I really appreciate everything that you've shared here and I I just want to double double triple quadruple endorse what you just said I went in doubt go back to the fundamentals learn them I like to say that like everybody on Star Trek like when you see Jordy you know working in the engine room and stuff like they understand the stack they understand what's going on in the ship and like how all these different systems work they spent the time to learn it they's not like you know like they're not just grasping the dark like education will have progressed dramatically by then they'll be able to hold a whole lot more facts and and understanding models in their mind of how reality works and they will be able to just just met like I was like the point at every every few years they have to kind of change the criteria of like the IQ test not that I put a lot of stock in IQ test but because people just get give you these margarine smarter and smarter with every generation wherever you like you know few years and that's gonna accelerate as we have access to more information as we're like walking around listening to podcasts like this maybe even a double speed you know all day while we're getting things done and just like our information that gets more and more enriched we become you know more deep thinkers and we we think on different levels and we don't just have like our little biases in our midst of information that we carry but we progress as human beings and I think as that happens you know human society is just gonna become more and more competent and more and more curious and like this virtue is going to continue to pick up and we're gonna use these tools to continue to extend our own understanding of the world and our own intelligence and I think that is the profound goodness in the world is people feeling curious to people following it and not having the intellectual poverty of your like there was a time when it was estimated that like the typical you know American out on the front of your living in a log cabin the amount of information they might encounter in their entire life would be the equivalent of like one day's you know Wall Street Journal and think about all the information you have access to now and all the ways that you can consume it while you're just chilling your eating your popcorn relaxing on the couch and you're learning about you know AI machine learning stuff like that whatever topic you're interested in learning and so I just encourage you to continue to build out your skills the way E-Fan has been working very hard to we didn't even go into your background but I'm sure it's exceptional and interesting because you don't get to like Google's machine learning team but you don't get to Stanford working as a researcher just by accident I'm sure you work very hard to get where you are and at some point I would like to have you back on and we can we can go warm into that but I just want to leave everybody with the thought of you know no matter what happens fortune favors the prepared and you can continue to get more and more prepared by building up your fundamental skills precisely as E-Fan encouraged you to do so thank you so much for coming on the show man and with that I wish you all a fantastic week and until next week happy codingï¿½ï¿½